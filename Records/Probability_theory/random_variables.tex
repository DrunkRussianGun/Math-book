\section{Случайные величины}
\index{Величины!случайные} \textbf{Случайной величиной} называется числовая переменная, которая принимает свои значения случайным образом.

Случайная величина называется \textbf{дискретной}, если она принимает конечное или счётно бесконечное количество значений.

Случайная величина называется \textbf{непрерывной}, если она принимает несчётно бесконечное количество значений.

\index{Распределение} \textbf{Законом распределения случайной величины~$X$} называется зависимость между её возможными значениями и соответствующими им вероятностями, обозначаемыми $P(X = x_i)$, где $x_i$~--- значение случайной величины.
\begin{enumerate}
	\item Случайная величина имеет \textbf{равномерное} распределение, если она принимает свои значения с одинаковой вероятностью.
	
	\item Рассмотрим схему Бернулли для $n$ испытаний с вероятностью <<успеха>> $p$.
	Случайная величина $X = \{ \text{число } \allowbreak \text{успехов} \}$, принимающая значения $0, 1, \ldots, n$, имеет \textbf{биномиальное} распределение $P(X = k) = C_n^k \opbr\cdot p^k \opbr\cdot (1 \opbr- p)^{n-k}$.
	
	\item Рассмотрим серию независимых подобных испытаний, в каждом из которых с постоянной вероятностью $p$ может произойти событие~$A = \{ \text{<<успех>>} \}$.
	Случайная величина $X = \{ \text{число проведённых испытаний до } \allowbreak \text{наступления события } A \}$, принимающая значения $1, 2, \ldots$, имеет \textbf{геометрическое} распределение $P(X = k) \opbr= p (1 - p)^{k-1}$.
	
	\item Пусть среди $n$ элементов есть $s$ элементов I типа.
	Случайная величина $X = \{ \text{число элементов I типа среди } m \allowbreak \text{ случайно выбранных} \}$, принимающая значения $0, 1, \ldots, \min \{ s, m \}$, имеет \textbf{гипергеометрическое} распределение $P(X = t) \opbr= \dfrac{C_s^t \cdot C_{n-s}^{m-t}}{C_n^m}$.
\end{enumerate}

\subsection{Функция распределения}
\index{Функция!распределения} \textbf{Функцией распределения случайной величины~$X$} называется функция $F(x) = P(X < x)$.
Свойства функции распределения:
\begin{enumerate}
	\item $D(F) = \mathbb R$
	
	\item $E(F) = [0; 1]$
	
	\item $P(x_1 \leqslant X < x_2) = F(x_2) - F(x_1)$
	\begin{proof}
	Пусть событие $A = \{ X < x_1 \}, B = \{ x_1 \leqslant X < x_2 \}, C = \{ X < x_2 \}$, тогда
	\begin{equation*}
	C = A + B \Rightarrow
	P(C) = P(A + B) \Rightarrow
	P(C) = P(A) + P(B) \Rightarrow
	\end{equation*}
	\begin{equation*}
	\Rightarrow P(x_1 \leqslant X < x_2) =
	P(B) =
	P(C) - P(A) =
	P(X < x_2) - P(X < x_1) =
	F(x_2) - F(x_1)
	\end{equation*}
	\end{proof}
	
	\item $F(x)$~--- неубывающая функция.
	\begin{proof}
	Пусть $x_1 < x_2$, тогда
	$P(x_1 \leqslant X < x_2) \geqslant 0 \Rightarrow
	F(x_2) - F(x_1) \geqslant 0 \Rightarrow
	F(x_1) \leqslant F(x_2)$.
	\end{proof}
	
	\item $\lim\limits_{x \to -\infty} F(x) = 0$
	\begin{proof}
	$\lim\limits_{x \to -\infty} F(x) =
	\lim\limits_{x \to -\infty} P(X < x) =
	P(X < -\infty) =
	P(\varnothing) =
	0$, где $\varnothing$~--- невозможное событие.
	\end{proof}
	
	\item $\lim\limits_{x \to +\infty} F(x) = 1$
	\begin{proof}
	$\lim\limits_{x \to +\infty} F(x) =
	\lim\limits_{x \to +\infty} P(X < x) =
	P(X < +\infty) =
	P(\Omega) =
	1$, где $\Omega$~--- достоверное событие.
	\end{proof}
\end{enumerate}

\subsection{Функция плотности вероятности}
\index{Функция!плотности вероятности} \textbf{Функцией плотности вероятности} непрерывной \textbf{случайной величины~$X$}, имеющей дифференцируемую функцию распределения~$F(x)$, называется функция $f(x) = F'(x)$.

Свойства функции плотности вероятности:
\begin{enumerate}
	\item $\forall x \in \mathbb R \ f(x) \geqslant 0$
	\begin{proof}
	$f(x) = F'(x) \geqslant 0$, т.\,к. $F(x)$ не убывает.
	\end{proof}
	
	\item $P(x_1 \leqslant X < x_2) = \int\limits_{x_1}^{x_2} f(x)\,dx$
	\begin{proof}
	$P(x_1 \leqslant X < x_2) =
	F(x_2) - F(x_1) =
	\int\limits_{x_1}^{x_2} F'(x)\,dx =
	\int\limits_{x_1}^{x_2} f(x)\,dx$.
	\end{proof}
	
	\item $\int\limits_{-\infty}^{+\infty} f(x)\,dx = 1$
	\begin{proof}
	$\int\limits_{-\infty}^{+\infty} f(x)\,dx =
	\lim\limits_{a \to +\infty} \int\limits_{-a}^a F'(x)\,dx =
	\lim\limits_{a \to +\infty} (F(a) - F(-a)) =
	1 - 0 =
	1$.
	\end{proof}
\end{enumerate}

\subsection{Числовые характеристики}
Далее для дискретной случайной величины
\begin{itemize}
	\item $x_i$~--- $i$"~е возможное значение;
	\item $p_i$~--- соответствующая $x_i$ вероятность;
	\item $n$~--- количество возможных значений (может быть счётно бесконечным, тогда $n = \infty$).
\end{itemize}

\index{Математическое ожидание} \textbf{Математическим ожиданием случайной величины~$X$} называется среднее её возможных значений и обозначается $M[X]$.
\begin{itemize}
	\item $\displaystyle M[X] = \sum_{i=1}^n p_i x_i$ для дискретной случайной величины.
	\item $\displaystyle M[X] = \int_{-\infty}^{+\infty} x f(x)\,dx$ для непрерывной случайной величины.
\end{itemize}

Пусть $C$~--- произвольная константа, $X, Y$~--- случайные величины.
Свойства математического ожидания:
\begin{enumerate}
	\item $M[C] = C$
	
	\item $M[CX] = C \cdot M[X]$
	\begin{proof}[для дискретной случайной величины]
	\begin{equation*}
	M[CX] =
	\sum_{i=1}^n p_i (C x_i) =
	C \sum_{i=1}^n p_i x_i =
	C \cdot M[X]
	\end{equation*}
	\end{proof}
	
	\item $M[X + C] = M[X] + C$
	\begin{proof}[для дискретной случайной величины]
	\begin{equation*}
	M[X + C] =
	\sum_{i=1}^n p_i (x_i + C) =
	\sum_{i=1}^n p_i x_i + C \sum_{i=1}^n p_i =
	M[X] + C
	\end{equation*}
	\end{proof}
	
	\item $M[X + Y] = M[X] + M[Y]$
	\begin{proof}[для дискретной случайной величины]
	\begin{equation*}
	M[X + Y] =
	\sum_{i=1}^n \sum_{j=1}^m p_{ij} (x_i + y_j) =
	\sum_{i=1}^n \sum_{j=1}^m p_{ij} x_i + \sum_{i=1}^n \sum_{j=1}^m p_{ij} y_j =
	\end{equation*}
	\begin{equation*}
	= \sum_{i=1}^n x_i \sum_{j=1}^m p_{ij} + \sum_{j=1}^m y_j \sum_{i=1}^n p_{ij} =
	\sum_{i=1}^n p_i x_i + \sum_{j=1}^m p_j y_j =
	M[X] + M[Y]
	\end{equation*}
	\end{proof}
	
	\item $M[XY] = M[X] \cdot M[Y]$, где $X, Y$~--- независимые случайные величины.
\end{enumerate}

\index{Дисперсия} \textbf{Дисперсией случайной величины~$X$} называется среднее квадратов отклонений значений случайной величины от её математического ожидания и обозначается $D[X]$.
\begin{itemize}
	\item $\displaystyle D[X] = \sum_{i=1}^n p_i (x_i - M[X])^2$ для дискретной случайной величины.
	\item $\displaystyle D[X] = \int_{-\infty}^{+\infty} (x - M[X])^2 f(x)\,dx$ для непрерывной случайной величины.
	\item $\displaystyle D[X] = M\left[(X - M[X])^2\right]$.
\end{itemize}

Пусть $C$~--- произвольная константа, $X$~--- случайная величина.
Свойства дисперсии:
\begin{enumerate}
	\item $D[C] = 0$
	
	\item $D[X + C] = D[X]$
	\begin{proof}
	\begin{equation*}
	D[X + C] =
	M\left[(X + C - M[X + C])^2\right] =
	M\left[(X - M[X] + C - C)^2\right] =
	M\left[(X - M[X])^2\right] =
	D[X]
	\end{equation*}
	\end{proof}
	
	\item $D[CX] = C^2 \cdot D[X]$
	\begin{proof}
	\begin{equation*}
	D[CX] =
	M\left[(CX - M[CX])^2\right] =
	M\left[(C(X - M[X]))^2\right] =
	M\left[C^2 \cdot (X - M[X])^2\right] =
	C^2 \cdot D[X]
	\end{equation*}
	\end{proof}
	
	\item $D[X] = M[X^2] - (M[X])^2$
	\begin{proof}
	\begin{equation*}
	D[X] =
	M\left[(X - M[X])^2\right] =
	M\left[X^2 - 2X \cdot M[X] + (M[X])^2\right] =
	\end{equation*}
	\begin{equation*}
	= M\left[X^2\right] - 2M[X] \cdot M[X] + (M[X])^2 =
	M\left[X^2\right] - (M[X])^2
	\end{equation*}
	\end{proof}
	
	\item $D[X + Y] = D[X] + D[Y]$, где $X, Y$~--- независимые случайные величины.
\end{enumerate}

\index{Отклонение!среднее квадратичное} \textbf{Средним квадратичным отклонением случайной величины~$X$} называется показатель рассеивания значений случайной величины относительно её математического ожидания и обозначается $\sigma[X]$.
\begin{itemize}
	\item $\displaystyle \sigma[X] = \sqrt{D[X]}$.
\end{itemize}

\subsection{Равномерное распределение}
\index{Распределение!равномерное} Случайная величина~$X$, непрерывная на~$[a; b]$, имеет \textbf{равномерное} распределение, если её функция плотности вероятности имеет вид $f(x) =
\begin{cases}
0, & x < a \\
\frac1{b - a}, & a \leqslant x \leqslant b \\
0, & x > b
\end{cases}$.

Свойства равномерного распределения:
\begin{enumerate}
	\item $\displaystyle M[X] = \frac{a + b}2$
	\begin{proof}
	\begin{equation*}
	M[X] =
	\int_a^b \frac{x}{b - a}\,dx =
	\frac1{b - a} \cdot \frac{b^2 - a^2}2 =
	\frac{a + b}2
	\end{equation*}
	\end{proof}
	
	\item $\displaystyle D[X] = \frac{(b - a)^2}{12}$
	\begin{proof}
	\begin{equation*}
	D[X] =
	\int_a^b \frac{x^2}{b - a}\,dx - \frac{(a + b)^2}4 =
	\frac{a^2 + ab + b^2}3 - \frac{(a + b)^2}4 =
	\frac{4a^2 + 4ab + 4b^2 - 3a^2 - 6ab - 3b^2}{12} =
	\frac{(b - a)^2}{12}
	\end{equation*}
	\end{proof}
	
	\item $\displaystyle F(x) =
	\begin{cases}
	0, & x < a \\
	\frac{x - a}{b - a}, & a \leqslant x \leqslant b \\
	1, & x > b
	\end{cases}$
	\begin{proof}
	Для $a \leqslant x \leqslant b$
	\begin{equation*}
	F(x) =
	\int_a^x \frac1{b - a}\,dt =
	\left. \frac{t}{b - a} \right|_a^x =
	\frac{x - a}{b - a}
	\end{equation*}
	\end{proof}
\end{enumerate}

\subsection{Показательное распределение}
\index{Распределение!показательное} \index{Распределение!экспоненциальное} Случайная величина~$X$ имеет \textbf{показательное} (\textbf{экспоненциальное}) распределение, если её функция плотности вероятности имеет вид $f(x) =
\begin{cases}
0, & x < 0 \\
\lambda e^{-\lambda x}, & x \geqslant 0
\end{cases}$,
где $\lambda > 0$.

Свойства показательного распределения:
\begin{enumerate}
	\item $\displaystyle F(x) =
	\begin{cases}
	0, & x < 0 \\
	1 - e^{-\lambda x}, & x \geqslant 0
	\end{cases}$
	\begin{proof}
	Для $x < 0$ очевидно.
	Для $x \geqslant 0$
	$\displaystyle F(x) =
	\int_{-\infty}^x f(x)\,dx =
	\int_0^x \lambda e^{-\lambda x}\,dx =
	\left. -e^{-\lambda x} \right|_0^x =
	1 - e^{-\lambda x}$.
	\end{proof}
	
	\item $\displaystyle P(a \leqslant X < b) = e^{-\lambda a} - e^{-\lambda b}$
	
	\item $\displaystyle M[X] = \frac1\lambda$
	\begin{proof}
	$\displaystyle M[X] =
	\int_0^{+\infty} x\,e^{-\lambda x}\,dx =
	\frac1\lambda$.
	\end{proof}
	
	\item $\displaystyle D[X] = \frac1{\lambda^2}$
	\begin{proof}
	$\displaystyle D[X] =
	M[X^2] - (M[X])^2 =
	\int_0^{+\infty} \lambda x^2\,e^{-\lambda x}\,dx - \frac1{\lambda^2} =
	\frac1{\lambda^2}$.
	\end{proof}
	
	\item $\displaystyle \sigma[X] = \frac1\lambda$
\end{enumerate}

Пусть $T$~--- время безотказной работы некоторого устройства, тогда вероятность отказа в момент времени $t$ равна $P(T \leqslant t) = F(t) = 1 - e^{-\lambda t}$.
Отсюда вероятность отсутствия отказов за время $t$ равна $P(T > t) = 1 - P(T \leqslant t) = e^{-\lambda t}$.

\index{Функция!надёжности} Функция $R(t) = P(T > t) = e^{-\lambda t}$ называется \textbf{функцией надёжности}.

\subsection{Нормальное распределение}
\index{Распределение!нормальное} \index{Распределение!гауссовское} Случайная величина~$X$ имеет \textbf{нормальное} (\textbf{гауссовское}) распределение, если её функция плотности вероятности имеет вид
\begin{equation*}
f(x) = \frac1{\sigma \sqrt{2 \pi}} \cdot e^{-\frac{(x - a)^2}{2 \sigma^2}}
\end{equation*}

Свойства нормального распределения:
\begin{enumerate}
	\item $M[X] = a$
	\begin{proof}
	\begin{equation*}
	M[X] =
	\frac1{\sigma \sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} x e^{-\frac{(x - a)^2}{2 \sigma^2}}\,dx \;
	\left| \text{Пусть } \frac{x - a}\sigma = t, \text{ тогда } x = \sigma t + a, \ dx = \sigma\,dt \right| =
	\frac1{\sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} (\sigma t + a) e^{-\frac{t^2}2}\,dt =
	\end{equation*}
	\begin{equation*}
	= \frac{a}{\sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} e^{-\frac{t^2}2}\,dt - \frac\sigma{\sqrt{2 \pi}} \cdot \lim_{b \to +\infty} \left. e^{-\frac{t^2}2} \right|_{-b}^b =
	\left| \lim_{b \to +\infty} \left. e^{-\frac{t^2}2} \right|_{-b}^b = 0, \text{ т.\,к. функция } e^{-\frac{t^2}2} \text{ чётная} \right|
	\end{equation*}
	\begin{equation*}
	= \frac{a}{\sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} e^{-\frac{t^2}2}\,dt =
	a \cdot (\Phi(+\infty) - \Phi(-\infty)) =
	a
	\end{equation*}
	\end{proof}
	
	\item $D[X] = \sigma^2$
	\begin{proof}
	\begin{equation*}
	D[X] =
	\frac1{\sigma \sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} (x - a)^2 e^{-\frac{(x - a)^2}{2 \sigma^2}}\,dx \;
	\left| \text{Пусть } \frac{x - a}\sigma = t, \text{ тогда } x = \sigma t + a, \ dx = \sigma\,dt \right| =
	\frac{\sigma^2}{\sqrt{2 \pi}} \cdot \int_{-\infty}^{+\infty} t \cdot t e^{-\frac{t^2}2}\,dt =
	\end{equation*}
	\begin{equation*}
	= \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \left(-\lim_{b \to +\infty} \left. t e^{-\frac{t^2}2} \right|_{-b}^b + \int_{-\infty}^{+\infty} e^{-\frac{t^2}2}\,dt \right) =
	\sigma^2 \cdot (\Phi(+\infty) - \Phi(-\infty)) - \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \lim_{b \to +\infty} 2b\,e^{-\frac{b^2}2} =
	\end{equation*}
	\begin{equation*}
	= \sigma^2 - \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \lim_{b \to +\infty} 2b\,e^{-\frac{b^2}2} =
	\sigma^2 - \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \lim_{b \to +\infty} \frac{2b}{e^{\frac{b^2}2}} =
	\sigma^2
	\end{equation*}
	\end{proof}
	
	\item $\sigma[X] = \sigma$
	
	\item $\displaystyle P(\alpha \leqslant X < \beta) = \Phi\left(\frac{\beta - a}\sigma\right) - \Phi\left(\frac{\alpha - a}\sigma\right)$
	\begin{proof}
	\begin{equation*}
	P(\alpha \leqslant X < \beta) =
	\frac1{\sigma \sqrt{2 \pi}} \cdot \int_\alpha^\beta e^{-\frac{(x - a)^2}{2 \sigma^2}}\,dx \;
	\left| \text{Пусть } \frac{x - a}\sigma = t, \text{ тогда } x = \sigma t + a, \ dx = \sigma\,dt \right| =
	\frac1{\sqrt{2 \pi}} \cdot \int_{\frac{\alpha - a}\sigma}^{\frac{\beta - a}\sigma} e^{-\frac{t^2}2}\,dt =
	\end{equation*}
	\begin{equation*}
	= \frac1{\sqrt{2 \pi}} \cdot \int_0^{\frac{\beta - a}\sigma} e^{-\frac{t^2}2}\,dt - \frac1{\sqrt{2 \pi}} \cdot \int_0^{\frac{\alpha - a}\sigma} e^{-\frac{t^2}2}\,dt =
	\Phi\left(\frac{\beta - a}\sigma\right) - \Phi\left(\frac{\alpha - a}\sigma\right)
	\end{equation*}
	\end{proof}
	
	\item $\displaystyle P(|X - a| < k) = 2 \Phi\left(\frac{k}\sigma\right)$
	\begin{proof}
	\begin{equation*}
	P(|X - a| < k) =
	P(-k < X - a < k) =
	P(a - k < X < a + k) =
	\end{equation*}
	\begin{equation*}
	= \Phi\left(\frac{a + k - a}\sigma\right) - \Phi\left(\frac{a - k - a}\sigma\right) =
	\Phi\left(\frac{k}\sigma\right) - \Phi\left(-\frac{k}\sigma\right) =
	2\Phi\left(\frac{k}\sigma\right)
	\end{equation*}
	\end{proof}
\end{enumerate}

\subsection{Корреляция}
\index{Корреляция} \textbf{Корреляцией} называется зависимость между случайными величинами, когда изменение значений одной из них приводит к изменению соответствующих значений другой.

Корреляция называется \textbf{положительной}/\textbf{отрицательной}, если при увеличении значения одной случайной величины увеличиваются/уменьшаются усреднённые показатели другой. 

\index{Величины!случайные!независимые} Случайные величины $X$ и $Y$ называются \textbf{независимыми}, если изменение значений одной из них не влияет на значения другой.
При этом $P(X < x \lAnd Y < y) = P(X < x) \cdot P(Y < y)$.

\index{Момент!корреляционный} \textbf{Корреляционным моментом случайных величин $X$ и $Y$} называется $K[X, Y] = M[(X - M[X]) (Y - M[Y])]$.

Свойства корреляционного момента:
\begin{enumerate}
	\item $K[X, X] = D[X]$
	
	\item $K[X, Y] = M[XY] - M[X] \cdot M[Y]$
	\begin{proof}
	\begin{equation*}
	K[X, Y] =
	M[(X - M[X]) (Y - M[Y])] =
	M[XY - M[X] \cdot Y - X \cdot M[Y] + M[X] \cdot M[Y]] =
	\end{equation*}
	\begin{equation*}
	= M[XY] - M[X] \cdot M[Y] - M[Y] \cdot M[X] + M[X] \cdot M[Y] =
	M[XY] - M[X] \cdot M[Y]
	\end{equation*}
	\end{proof}
\end{enumerate}

\index{Коэффициент!линейной корреляции} \textbf{Коэффициентом линейной корреляции случайных величин $X$ и $Y$} называется $\displaystyle R_{X,Y} = \frac{K[X, Y]}{\sigma[X] \sigma[Y]}$.

Свойства коэффициента линейной корреляции:
\begin{itemize}
	\item $\displaystyle R_{X,Y} = \frac{M[XY] - M[X] \cdot M[Y]}{\sigma[X] \sigma[Y]}$;

	\item $-1 \leqslant R_{X,Y} \leqslant 1$;
	
	\item $R_{X,Y} < 0$ для отрицательной корреляции $X$ и $Y$;
	
	\item $R_{X,Y} > 0$ для положительной корреляции $X$ и $Y$;
	
	\item $R_{X,Y} = 0$ для независимых $X$ и $Y$.
\end{itemize}

\subsection{Закон больших чисел}
\textbf{Закон больших чисел}~--- это принцип, устанавливающий связь между случайностью и закономерностью.
Согласно данному принципу, при большом числе испытаний случайное явление приобретает закономерные свойства.

Пусть $X_1, \ldots, X_n$~--- независимые случайные величины, для которых $M[X_i] = m$, $D[X_i] = \sigma^2$.
Рассмотрим их среднее арифметическое $\overline X = \frac1n \sum\limits_{i=1}^n X_i$.
\begin{enumerate}
	\item $M\left[\overline X\right] = m$
	\begin{proof}
	$M\left[\overline X\right] =
	M\left[\frac1n \sum\limits_{i=1}^n X_i\right] =
	\frac1n \sum\limits_{i=1}^n M[X_i] =
	\frac1n \sum\limits_{i=1}^n m =
	m$.
	\end{proof}
	
	\item $D\left[\overline X\right] = \dfrac{\sigma^2}n$
	\begin{proof}
	$D\left[\overline X\right] =
	D\left[\frac1n \sum\limits_{i=1}^n X_i\right] =
	\frac1{n^2} D\left[\sum\limits_{i=1}^n X_i\right] \;
	\left| X_1, \ldots, X_n \text{ независимы} \right| =
	\frac1{n^2} \sum\limits_{i=1}^n D[X_i] =
	\dfrac{\sigma^2}n$.
	\end{proof}
\end{enumerate}

\index{Неравенство!Чебышёва}
\begin{theorem}[неравенство Чебышёва]
Пусть $k > 0$, $X$~--- случайная величина, $M[X] = m$, $D[X] = \sigma^2$, тогда $P(|X - m| \geqslant k) \leqslant \dfrac{\sigma^2}{k^2}$.
\end{theorem}
\begin{proof}[для дискретной случайной величины]
\begin{equation*}
\sigma^2 =
\sum_{i=1}^n p_i (x_i - m)^2 \geqslant
\sum_{|x_i - m| \geqslant k} p_i (x_i - m)^2 \geqslant
k^2 \sum_{|x_i - m| \geqslant k} p_i =
k^2 P(|X - m| \geqslant k) \Rightarrow
P(|X - m| \geqslant k) \leqslant \frac{\sigma^2}{k^2}
\end{equation*}
\end{proof}

\begin{consequent}
Для среднего арифметического $\overline X$ независимых случайных величин $X_1, \ldots, X_n$ и $k > 0$ выполняется неравенство $P(|\overline X - m| \geqslant k) \leqslant \dfrac{\sigma^2}{n k^2}$.
\end{consequent}

\subsection{Центральная предельная теорема}
\index{Теорема!Ляпунова} \index{Теорема!центральная предельная}
\begin{theorem}[Ляпунова, центральная предельная теорема]
Пусть $X_1, \ldots, X_n$~--- независимые случайные величины, для которых:
\begin{itemize}
	\item $M\left[X_i\right] = m_i$;
	\item $D\left[X_i\right] = \sigma_i^2$;
	\item $\displaystyle \lim_{n \to \infty} \frac{\sum\limits_{i=1}^n M\left[(X_i - m_i)^3\right]}{\left(\sum\limits_{i=1}^n \sigma_i^2\right)^{\frac32}} = 0$.
\end{itemize}
Тогда при увеличении~$n$ случайная величина $V = \sum\limits_{i=1}^n X_i$ стремится к нормальному распределению c $M[V] = \sum\limits_{i=1}^n m_i$ и $D[V] = \sum\limits_{i=1}^n \sigma_i^2$.
\end{theorem}